{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://jupyterhub.readthedocs.io/en/stable/installation-guide.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cluster using kops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********************************************************************************\n",
      "\n",
      "A new kubernetes version is available: 1.10.5\n",
      "Upgrading is recommended (try kops upgrade cluster)\n",
      "\n",
      "More information: https://github.com/kubernetes/kops/blob/master/permalinks/upgrade_k8s.md#1.10.5\n",
      "\n",
      "*********************************************************************************\n",
      "\n",
      "kops has set your kubectl context to jupyterhub.k8s.local\n",
      "\n",
      "Cluster is starting.  It should be ready in a few minutes.\n",
      "\n",
      "Suggestions:\n",
      " * validate cluster: kops validate cluster\n",
      " * list nodes: kubectl get nodes --show-labels\n",
      " * ssh to the master: ssh -i ~/.ssh/id_rsa admin@api.jupyterhub.k8s.local\n",
      " * the admin user is specific to Debian. If not using Debian please use the appropriate user based on your OS.\n",
      " * read about installing addons at: https://github.com/kubernetes/kops/blob/master/docs/addons.md.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1003 21:27:14.341850   12769 create_cluster.go:1351] Using SSH public key: /Users/btsui/.ssh/id_rsa.jupyterhub.pub\n",
      "I1003 21:27:15.417740   12769 create_cluster.go:480] Inferred --cloud=aws from zone \"us-west-2a\"\n",
      "I1003 21:27:15.717691   12769 subnets.go:184] Assigned CIDR 172.20.32.0/19 to subnet us-west-2a\n",
      "I1003 21:27:15.717724   12769 subnets.go:184] Assigned CIDR 172.20.64.0/19 to subnet us-west-2b\n",
      "I1003 21:27:15.717734   12769 subnets.go:184] Assigned CIDR 172.20.96.0/19 to subnet us-west-2c\n",
      "I1003 21:27:18.587214   12769 apply_cluster.go:505] Gossip DNS: skipping DNS validation\n",
      "I1003 21:27:19.245704   12769 executor.go:103] Tasks: 0 done / 81 total; 30 can run\n",
      "I1003 21:27:20.149052   12769 vfs_castore.go:735] Issuing new certificate: \"ca\"\n",
      "I1003 21:27:20.267319   12769 vfs_castore.go:735] Issuing new certificate: \"apiserver-aggregator-ca\"\n",
      "I1003 21:27:21.123302   12769 executor.go:103] Tasks: 30 done / 81 total; 26 can run\n",
      "I1003 21:27:22.025680   12769 vfs_castore.go:735] Issuing new certificate: \"kube-proxy\"\n",
      "I1003 21:27:22.122026   12769 vfs_castore.go:735] Issuing new certificate: \"kops\"\n",
      "I1003 21:27:22.179439   12769 vfs_castore.go:735] Issuing new certificate: \"apiserver-proxy-client\"\n",
      "I1003 21:27:22.193230   12769 vfs_castore.go:735] Issuing new certificate: \"apiserver-aggregator\"\n",
      "I1003 21:27:22.202908   12769 vfs_castore.go:735] Issuing new certificate: \"kubelet-api\"\n",
      "I1003 21:27:22.350856   12769 vfs_castore.go:735] Issuing new certificate: \"kube-controller-manager\"\n",
      "I1003 21:27:22.365825   12769 vfs_castore.go:735] Issuing new certificate: \"kube-scheduler\"\n",
      "I1003 21:27:22.415106   12769 vfs_castore.go:735] Issuing new certificate: \"kubecfg\"\n",
      "I1003 21:27:22.481093   12769 vfs_castore.go:735] Issuing new certificate: \"kubelet\"\n",
      "I1003 21:27:23.480385   12769 executor.go:103] Tasks: 56 done / 81 total; 21 can run\n",
      "I1003 21:27:24.293166   12769 launchconfiguration.go:380] waiting for IAM instance profile \"nodes.jupyterhub.k8s.local\" to be ready\n",
      "I1003 21:27:24.344257   12769 launchconfiguration.go:380] waiting for IAM instance profile \"masters.jupyterhub.k8s.local\" to be ready\n",
      "I1003 21:27:35.529703   12769 executor.go:103] Tasks: 77 done / 81 total; 3 can run\n",
      "I1003 21:27:36.711256   12769 vfs_castore.go:735] Issuing new certificate: \"master\"\n",
      "I1003 21:27:37.248589   12769 executor.go:103] Tasks: 80 done / 81 total; 1 can run\n",
      "I1003 21:27:37.751968   12769 executor.go:103] Tasks: 81 done / 81 total; 0 can run\n",
      "I1003 21:27:38.157752   12769 update_cluster.go:290] Exporting kubecfg for cluster\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export NAME=jupyterhub.k8s.local\n",
    "\n",
    "kops create cluster $NAME \\\n",
    "  --zones=us-west-2a,us-west-2b,us-west-2c \\\n",
    "  --authorization RBAC \\\n",
    "  --master-size t2.xlarge \\\n",
    "  --master-volume-size 20 \\\n",
    "  --node-size t2.xlarge \\\n",
    "  --node-volume-size 20 \\\n",
    "  --node-count 1 \\\n",
    "  --ssh-public-key $HOME/.ssh/id_rsa.jupyterhub.pub \\\n",
    "  --yes\n",
    "sleep 360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Tiller (Cluster version of pip install )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serviceaccount \"tiller\" created\n",
      "clusterrolebinding.rbac.authorization.k8s.io \"tiller\" created\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl --namespace kube-system create serviceaccount tiller\n",
    "kubectl create clusterrolebinding tiller --clusterrole cluster-admin --serviceaccount=kube-system:tiller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$HELM_HOME has been configured at /Users/btsui/.helm.\n",
      "\n",
      "Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster.\n",
      "\n",
      "Please note: by default, Tiller is deployed with an insecure 'allow unauthenticated users' policy.\n",
      "To prevent this, run `helm init` with the --tiller-tls-verify flag.\n",
      "For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation\n",
      "Happy Helming!\n"
     ]
    }
   ],
   "source": [
    "!helm init --service-account tiller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.extensions \"tiller-deploy\" patched\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "!sleep 10\n",
    "kubectl patch deployment tiller-deploy --namespace=kube-system --type=json --patch='[{\"op\": \"add\", \"path\": \"/spec/template/spec/containers/0/command\", \"value\": [\"/tiller\", \"--listen=localhost:44134\"]}]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up EBS volumne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storageclass.storage.k8s.io \"gp2\" configured\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f storageclass.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sleep 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the DNS: \n",
    "\n",
    "https://console.aws.amazon.com/route53/home\n",
    "\n",
    "Choose Go to Record Sets.\n",
    "Choose Create Record Set.\n",
    "For Create Record Set, do the following:\n",
    "Leave the default name, which is the name of your domain.\n",
    "For Type, select A â€” IPv4 address.\n",
    "For Alias, choose Yes. An alias enables Route 53 to associate your domain name with an AWS resource, such as a load balancer.\n",
    "Choose Alias Target. Select your load balancer from the list. The console adds the dualstack prefix.\n",
    "For Routing Policy, select Simple.\n",
    "Leave Evaluate Target Health set to No.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up EFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### delete existing mount targets on EFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "efs = boto3.client('efs')\n",
    "\n",
    "efsId='fs-e1636448'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Dict in efs.describe_mount_targets(FileSystemId=efsId)['MountTargets']:\n",
    "    efs.delete_mount_target(MountTargetId=Dict['MountTargetId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mount targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new VPC ID: vpc-020d6c6d174e3674c\n"
     ]
    }
   ],
   "source": [
    "ec2 = boto3.resource('ec2')\n",
    "\n",
    "instances=list(ec2.instances.all())\n",
    "\n",
    "newVPC=pd.Series(list(map(lambda i:i.vpc_id,instances))).dropna().iloc[0]\n",
    "print ('new VPC ID:',newVPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "newSubnets=pd.Series(list(map(lambda i:i.subnet_id,instances))).dropna()#.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupIdL=[]\n",
    "for ec2 in instances:\n",
    "    if len(ec2.security_groups)>0:\n",
    "        groupIdL.append((ec2.security_groups[0]['GroupId'])) \n",
    "#newSgs=pd.Series(list(map(lambda i:i.security_groups[0]['GroupId'],instances))).dropna()#.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fs-e1636448', 1    subnet-03b6b36296cf45cb7\n",
       " 4    subnet-04aab7a6afc9f418a\n",
       " dtype: object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efsId,newSubnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    subnet-03b6b36296cf45cb7\n",
       "4    subnet-04aab7a6afc9f418a\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newSubnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sg-0edb0763f38225af9', 'sg-048d8df9c4c910075']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupIdL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newVPC=''\n",
    "for SubnetId in newSubnets:\n",
    "    efs.create_mount_target(FileSystemId=efsId,\n",
    "        SubnetId=SubnetId,SecurityGroups=groupIdL\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -O manifest.helm.yaml https://raw.githubusercontent.com/kubernetes-incubator/external-storage/master/aws/efs/deploy/manifest.yaml\n",
    "asdasdasd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mount NFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sleep 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import paramiko\n",
    "\n",
    "key = paramiko.RSAKey.from_private_key_file('/Users/btsui/.ssh/id_rsa.jupyterhub')\n",
    "client = paramiko.SSHClient()\n",
    "client.set_missing_host_key_policy(paramiko.AutoAddPolicy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b''\n",
      "b''\n",
      "b''\n",
      "b''\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "ec2 = boto3.resource('ec2')\n",
    "\n",
    "instances=list(ec2.instances.all())\n",
    "\n",
    "ec2=instances[0\n",
    "             ]\n",
    "\n",
    "for ec2 in instances:\n",
    "    if ec2.public_dns_name !='' :\n",
    "        # Connect/ssh to an instance\n",
    "        instance_ip=ec2.public_dns_name\n",
    "        #try:\n",
    "        # Here 'ubuntu' is user name and 'instance_ip' is public IP of EC2\n",
    "        client.connect(hostname=instance_ip, username=\"admin\", pkey=key)\n",
    "        # Execute a command(cmd) after connecting/ssh to an instance\n",
    "        cmd='mkdir ~/efs'\n",
    "        stdin, stdout, stderr = client.exec_command(cmd)\n",
    "        cmd='sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2 fs-e1636448.efs.us-west-2.amazonaws.com:/ ~/efs'\n",
    "        stdin, stdout, stderr = client.exec_command(cmd)\n",
    "        print (stdout.read())\n",
    "        print (stderr.read())\n",
    "        client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup jupyter hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Release \"jhub\" does not exist. Installing it now.\n",
      "NAME:   jhub\n",
      "LAST DEPLOYED: Wed Oct  3 21:42:01 2018\n",
      "NAMESPACE: jhub\n",
      "STATUS: DEPLOYED\n",
      "\n",
      "RESOURCES:\n",
      "==> v1beta1/PodDisruptionBudget\n",
      "NAME   MIN AVAILABLE  MAX UNAVAILABLE  ALLOWED DISRUPTIONS  AGE\n",
      "hub    1              N/A              0                    0s\n",
      "proxy  1              N/A              0                    0s\n",
      "\n",
      "==> v1/Secret\n",
      "NAME        TYPE    DATA  AGE\n",
      "hub-secret  Opaque  1     0s\n",
      "\n",
      "==> v1/PersistentVolumeClaim\n",
      "NAME        STATUS   VOLUME  CAPACITY  ACCESS MODES  STORAGECLASS  AGE\n",
      "hub-db-dir  Pending  gp2     0s\n",
      "\n",
      "==> v1/ServiceAccount\n",
      "NAME  SECRETS  AGE\n",
      "hub   1        0s\n",
      "\n",
      "==> v1/Service\n",
      "NAME          TYPE          CLUSTER-IP     EXTERNAL-IP  PORT(S)       AGE\n",
      "hub           ClusterIP     100.71.188.34  <none>       8081/TCP      0s\n",
      "proxy-api     ClusterIP     100.67.69.165  <none>       8001/TCP      0s\n",
      "proxy-public  LoadBalancer  100.70.67.13   <pending>    80:31469/TCP  0s\n",
      "\n",
      "==> v1beta2/Deployment\n",
      "NAME   DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE\n",
      "hub    1        1        1           0          0s\n",
      "proxy  1        1        1           0          0s\n",
      "\n",
      "==> v1/ConfigMap\n",
      "NAME        DATA  AGE\n",
      "hub-config  40    0s\n",
      "\n",
      "==> v1beta1/Role\n",
      "NAME  AGE\n",
      "hub   0s\n",
      "\n",
      "==> v1beta1/RoleBinding\n",
      "NAME  AGE\n",
      "hub   0s\n",
      "\n",
      "==> v1/Pod(related)\n",
      "NAME                    READY  STATUS             RESTARTS  AGE\n",
      "hub-5c789b49f7-pcb6x    0/1    Pending            0         0s\n",
      "proxy-64c555c54c-cwhrl  0/1    ContainerCreating  0         0s\n",
      "\n",
      "\n",
      "NOTES:\n",
      "Thank you for installing JupyterHub!\n",
      "\n",
      "Your release is named jhub and installed into the namespace jhub.\n",
      "\n",
      "You can find if the hub and proxy is ready by doing:\n",
      "\n",
      " kubectl --namespace=jhub get pod\n",
      "\n",
      "and watching for both those pods to be in status 'Ready'.\n",
      "\n",
      "You can find the public IP of the JupyterHub by doing:\n",
      "\n",
      " kubectl --namespace=jhub get svc proxy-public\n",
      "\n",
      "It might take a few minutes for it to appear!\n",
      "\n",
      "Note that this is still an alpha release! If you have questions, feel free to\n",
      "  1. Read the guide at https://z2jh.jupyter.org\n",
      "  2. Chat with us at https://gitter.im/jupyterhub/jupyterhub\n",
      "  3. File issues at https://github.com/jupyterhub/zero-to-jupyterhub-k8s/issues\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E1003 21:44:31.829819   12933 portforward.go:303] error copying from remote stream to local connection: readfrom tcp4 127.0.0.1:56619->127.0.0.1:56623: write tcp4 127.0.0.1:56619->127.0.0.1:56623: write: broken pipe\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "RELEASE=jhub\n",
    "NAMESPACE=jhub\n",
    "helm upgrade --install $RELEASE jupyterhub/jupyterhub \\\n",
    "  --namespace $NAMESPACE  \\\n",
    "  --version 0.7.0 \\\n",
    "  --values config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect DNS with load balancer IP\n",
    "* [DNS](https://console.aws.amazon.com/route53/home?region=us-west-2#resource-record-sets:Z3ALGFGOLRJSAE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport boto3\\n\\nclient53 = boto3.client('route53')\\nresponse = client53.change_resource_record_sets(\\n    HostedZoneId='Z1H1FL5HABSF5',\\n    ChangeBatch={\\n        'Comment': 'string',\\n        'Changes': [\\n            {\\n                'Action': 'UPSERT',\\n                'ResourceRecordSet': {\\n                    'Name': 'jupyterhub.hannahcarterlab.org.',\\n                    'Type': 'A',\\n                    #'SetIdentifier': 'string',\\n                    #'Weight': 123,\\n                    'Region': 'us-west-2',#'us-east-1'|'us-east-2'|'us-west-1'|'us-west-2'|'ca-central-1'|'eu-west-1'|'eu-west-2'|'eu-west-3'|'eu-central-1'|'ap-southeast-1'|'ap-southeast-2'|'ap-northeast-1'|'ap-northeast-2'|'ap-northeast-3'|'sa-east-1'|'cn-north-1'|'cn-northwest-1'|'ap-south-1',\\n                    #'Failover': 'PRIMARY'|'SECONDARY',\\n                    #'MultiValueAnswer': True|False,\\n                    #'TTL': 123,\\n                    'AliasTarget': {\\n                        'HostedZoneId': 'dualstack.a30f630e7c73411e8aec902ea44e5fc5-311761146.us-west-2.elb.amazonaws.com.',\\n                        'DNSName': 'jupyterhub.hannahcarterlab.org',\\n                        'EvaluateTargetHealth': False\\n                    },\\n                    #'HealthCheckId': 'string',\\n                    #'TrafficPolicyInstanceId': 'string'\\n                }\\n            },\\n        ]\\n    }\\n)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import boto3\n",
    "\n",
    "client53 = boto3.client('route53')\n",
    "response = client53.change_resource_record_sets(\n",
    "    HostedZoneId='Z1H1FL5HABSF5',\n",
    "    ChangeBatch={\n",
    "        'Comment': 'string',\n",
    "        'Changes': [\n",
    "            {\n",
    "                'Action': 'UPSERT',\n",
    "                'ResourceRecordSet': {\n",
    "                    'Name': 'jupyterhub.hannahcarterlab.org.',\n",
    "                    'Type': 'A',\n",
    "                    #'SetIdentifier': 'string',\n",
    "                    #'Weight': 123,\n",
    "                    'Region': 'us-west-2',#'us-east-1'|'us-east-2'|'us-west-1'|'us-west-2'|'ca-central-1'|'eu-west-1'|'eu-west-2'|'eu-west-3'|'eu-central-1'|'ap-southeast-1'|'ap-southeast-2'|'ap-northeast-1'|'ap-northeast-2'|'ap-northeast-3'|'sa-east-1'|'cn-north-1'|'cn-northwest-1'|'ap-south-1',\n",
    "                    #'Failover': 'PRIMARY'|'SECONDARY',\n",
    "                    #'MultiValueAnswer': True|False,\n",
    "                    #'TTL': 123,\n",
    "                    'AliasTarget': {\n",
    "                        'HostedZoneId': 'dualstack.a30f630e7c73411e8aec902ea44e5fc5-311761146.us-west-2.elb.amazonaws.com.',\n",
    "                        'DNSName': 'jupyterhub.hannahcarterlab.org',\n",
    "                        'EvaluateTargetHealth': False\n",
    "                    },\n",
    "                    #'HealthCheckId': 'string',\n",
    "                    #'TrafficPolicyInstanceId': 'string'\n",
    "                }\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Release \"jhub\" has been upgraded. Happy Helming!\n",
      "LAST DEPLOYED: Wed Oct  3 21:45:28 2018\n",
      "NAMESPACE: jhub\n",
      "STATUS: DEPLOYED\n",
      "\n",
      "RESOURCES:\n",
      "==> v1beta2/Deployment\n",
      "NAME   DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE\n",
      "hub    1        1        1           1          1m\n",
      "proxy  1        1        1           1          1m\n",
      "\n",
      "==> v1beta1/PodDisruptionBudget\n",
      "NAME   MIN AVAILABLE  MAX UNAVAILABLE  ALLOWED DISRUPTIONS  AGE\n",
      "hub    1              N/A              0                    1m\n",
      "proxy  1              N/A              0                    1m\n",
      "\n",
      "==> v1/Pod(related)\n",
      "NAME                    READY  STATUS   RESTARTS  AGE\n",
      "hub-5c789b49f7-pcb6x    1/1    Running  0         1m\n",
      "proxy-64c555c54c-cwhrl  1/1    Running  0         1m\n",
      "\n",
      "==> v1/Secret\n",
      "NAME        TYPE    DATA  AGE\n",
      "hub-secret  Opaque  1     1m\n",
      "\n",
      "==> v1/ConfigMap\n",
      "NAME        DATA  AGE\n",
      "hub-config  40    1m\n",
      "\n",
      "==> v1/PersistentVolumeClaim\n",
      "NAME        STATUS  VOLUME                                    CAPACITY  ACCESS MODES  STORAGECLASS  AGE\n",
      "hub-db-dir  Bound   pvc-2f12dc3b-c790-11e8-89ed-02ed689d0de4  1Gi       RWO           gp2           1m\n",
      "\n",
      "==> v1/ServiceAccount\n",
      "NAME  SECRETS  AGE\n",
      "hub   1        1m\n",
      "\n",
      "==> v1beta1/Role\n",
      "NAME  AGE\n",
      "hub   1m\n",
      "\n",
      "==> v1beta1/RoleBinding\n",
      "NAME  AGE\n",
      "hub   1m\n",
      "\n",
      "==> v1/Service\n",
      "NAME          TYPE          CLUSTER-IP     EXTERNAL-IP       PORT(S)       AGE\n",
      "hub           ClusterIP     100.71.188.34  <none>            8081/TCP      1m\n",
      "proxy-api     ClusterIP     100.67.69.165  <none>            8001/TCP      1m\n",
      "proxy-public  LoadBalancer  100.70.67.13   a2f1ae5bbc790...  80:31469/TCP  1m\n",
      "\n",
      "\n",
      "NOTES:\n",
      "Thank you for installing JupyterHub!\n",
      "\n",
      "Your release is named jhub and installed into the namespace jhub.\n",
      "\n",
      "You can find if the hub and proxy is ready by doing:\n",
      "\n",
      " kubectl --namespace=jhub get pod\n",
      "\n",
      "and watching for both those pods to be in status 'Ready'.\n",
      "\n",
      "You can find the public IP of the JupyterHub by doing:\n",
      "\n",
      " kubectl --namespace=jhub get svc proxy-public\n",
      "\n",
      "It might take a few minutes for it to appear!\n",
      "\n",
      "Note that this is still an alpha release! If you have questions, feel free to\n",
      "  1. Read the guide at https://z2jh.jupyter.org\n",
      "  2. Chat with us at https://gitter.im/jupyterhub/jupyterhub\n",
      "  3. File issues at https://github.com/jupyterhub/zero-to-jupyterhub-k8s/issues\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "RELEASE=jhub\n",
    "\n",
    "helm upgrade $RELEASE jupyterhub/jupyterhub \\\n",
    "  --version=0.7.0 \\\n",
    "  --values config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl --namespace=jhub get pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /Users/btsui/GithubProject/CarterLabJupyterHub\n",
    "docker build -t jhubuserimage .\n",
    "docker tag jhubuserimage btsui/get-started:v1\n",
    "docker push btsui/get-started:v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my docker file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM jupyter/minimal-notebook:177037d09156\r\n",
      "RUN pip install nbgitpuller\r\n",
      "RUN jupyter serverextension enable --py nbgitpuller --sys-prefix\r\n",
      "RUN conda create --yes -n skymap jupyter python=3.6 pandas=0.23.4 seaborn=0.8.1 scikit-learn=0.19.1\r\n",
      "RUN conda install --yes -n skymap nb_conda_kernels\r\n",
      "RUN conda install --yes nb_conda_kernels\r\n",
      "\r\n",
      "\r\n",
      "#RUN conda install --yes astropy\r\n"
     ]
    }
   ],
   "source": [
    "!cat /Users/btsui/GithubProject/CarterLabJupyterHub/Docker/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Console short cut\n",
    "\n",
    "* [EC2](https://us-west-2.console.aws.amazon.com/ec2/v2/home?region=us-west-2#Instances:sort=availabilityZone)\n",
    "* [DNS](https://console.aws.amazon.com/route53/home?region=us-west-2#)\n",
    "* [EFS](https://us-west-2.console.aws.amazon.com/efs/home?region=us-west-2#/filesystems)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delete the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Delete mount targets first](#delete-existing-mount-targets-on-EFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! kops delete cluster jupyterhub.k8s.local --yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Kubernete dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[start kube server](startKubServer.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up dashboard\n",
    "\n",
    "!kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml\n",
    "\n",
    "!kubectl apply -f admin.yml\n",
    "\n",
    "!kubectl apply -f admin_previledge.yml\n",
    "\n",
    "!kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find load balancer IP name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%%bash\n",
    "kubectl describe service proxy-public  --namespace jhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                         STATUS    ROLES     AGE       VERSION\r\n",
      "ip-172-20-39-64.us-west-2.compute.internal   Ready     master    1d        v1.10.3\r\n",
      "ip-172-20-95-93.us-west-2.compute.internal   Ready     node      1d        v1.10.3\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get nodes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
